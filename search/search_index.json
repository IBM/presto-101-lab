{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#presto-workshop-getting-started-with-presto","title":"Presto Workshop - Getting Started with Presto","text":"<p>Welcome to our workshop! In this workshop, you\u2019ll learn the basics of Presto, the open-source SQL query engine. You\u2019ll get Presto running locally on your machine, connect data sources, and run some queries. This is a beginner-level workshop for software developers and engineers who are new to Presto. At the end of the workshop, you will understand how to federate queries using Presto. </p> <p>The goals of this workshop are:</p> <ul> <li>What is Presto and why you\u2019d use it</li> <li>How to write a Presto query</li> <li>How to create and deploy a Presto cluster on your machine using Docker</li> <li>How to add 2 data sources (MySQL and MongoDB) and query the data from them</li> <li>How to create dashboards/visualizations of your data</li> </ul>"},{"location":"#about-this-workshop","title":"About this workshop","text":"<p>The introductory page of the workshop is broken down into the following sections:</p> <ul> <li>Agenda</li> <li>Compatibility</li> <li>Technology Used</li> <li>Credits</li> </ul>"},{"location":"#agenda","title":"Agenda","text":"Prerequisite Prerequisites for the workshop Introduction Presto Introduction Lab 1: Set up Presto Set up a Presto cluster with 1 coordinator and 3 workers Lab 2: Set up Data Sources Set up 2 data source - MySQL and MongoDB Lab 3: Connect to Data Sources Set up 2 catalogs to connect to MySQL and MongoDB Lab 4: Data Visualization Visualize the data"},{"location":"#compatibility","title":"Compatibility","text":"<p>This workshop has been tested on the following platforms:</p> <ul> <li>Linux: Ubuntu 22.04</li> <li>MacOS</li> </ul>"},{"location":"#technology-used","title":"Technology Used","text":"<ul> <li>Docker: A container engine to run several applications in self-contained containers.</li> <li>Presto: Fast and Reliable SQL Engine for Data Analytics and the Open Lakehouse</li> <li>MySQL: A popular open-source relational database management system</li> <li>MongoDB: A document-oriented database</li> <li>Apache Zeppelin: Web-based notebook for interactive data analytics</li> </ul>"},{"location":"#credits","title":"Credits","text":"<ul> <li>Kiersten Stokes</li> <li>Yihong Wang</li> </ul>"},{"location":"introduction/","title":"Introduction","text":"<p>A data lakehouse is a data platform, which merges the best aspects of data warehouses and data lakes into one data management solution. If you are looking for an open-source solution for data lakehouse, Presto is the perfect choice. Presto is a fast and reliable SQL query engine for data analytics and the open lakehouse. It can be used in various use cases, like running interactive/ad hoc queries at sub-second performance for your high-volume apps, or lengthy ETL jobs that aggregate or join terabytes of data.</p> <p>Presto is designed to be adaptive, flexible, and extensible. The plugin mechanism it provides allows you to connect to different data sources. A single Presto query can combine data from multiple sources, archiving analytics across your entire organization. Dozens of connectors are available from the Presto community today. You can see the high-level architecture diagram below:</p> <p></p>"},{"location":"introduction/#features-of-presto","title":"Features of Presto","text":"<p>Here are the notable features of Presto that make it perfect for the data lakehouse platform.</p>"},{"location":"introduction/#adaptive-multi-tenant-system","title":"Adaptive Multi-tenant System","text":"<p>Presto is capable of running hundreds of concurrent queries and fully utilizing the CPUs, memory, and I/O on the cluster which can scale up to thousands of worker nodes.</p>"},{"location":"introduction/#extensible","title":"Extensible","text":"<p>It's easy to set up Presto to connect to many different data sources and run federated queries.</p>"},{"location":"introduction/#performance","title":"Performance","text":"<p>Presto is built for high performance. The key features include: - In-memory data processing and reduce Disk I/O latency. - Built-in query optimizations, including data layout awareness, predicate pushdown, inter-node parallelism, and etc. - Optimized stage and task scheduling - Resource management</p>"},{"location":"introduction/#getting-started","title":"Getting Started","text":"<p>To get set up a Presto cluster and try out its amazing features, you can go to prestodb.io where you can find the get started information. You can also find detailed documentation here. In the Installation section, it provides the instructions to set up simple configurations.</p> <p>In this workshop, you will use docker to spin up</p> <ul> <li>A Presto cluster using a coordinator and 3 workers</li> <li>A MySQL server with simple data</li> <li>A MongoDB with simple data</li> </ul> <p></p> <p>Without further ado, let's get started.</p>"},{"location":"lab-1/","title":"Set up Presto","text":"<p>In this section, you will: - Create a docker network to connect all containers that you are going to create - Set up a Presto cluster including   - A coordinator node   - 3 worker nodes</p> <p>This section is comprised of the following steps:</p> <ol> <li>Create a Presto cluster including:<ul> <li>A coordinator node</li> <li>3 worker nodes<ul> <li>worker1</li> <li>worker2</li> <li>worker3</li> </ul> </li> </ul> </li> <li>Check Presto UI</li> </ol>"},{"location":"lab-1/#1-create-a-presto-cluster","title":"1. Create a Presto cluster","text":"<p>Run the following command to bring up a Presto cluster which has 1 coordinator node and 3 worker nodes <pre><code>docker compose up -d\n</code></pre> The command pulls the latest <code>prestodb/presto</code> image and other images needed in the <code>./docker-compose.yml</code> Docker Compose file.</p> <p>You would see the outputs similar to the following: <pre><code>[+] Running 7/7\n \u2714 Container zeppelin      Running                                0.0s\n \u2714 Container worker3       Running                                0.0s\n \u2714 Container presto-mysql  Running                                0.0s\n \u2714 Container worker1       Running                                0.0s\n \u2714 Container presto-mongo  Running                                0.0s\n \u2714 Container worker2       Running                                0.0s\n \u2714 Container coordinator   Running                                0.0s\n</code></pre></p>"},{"location":"lab-1/#21-presto-coordinator","title":"2.1 Presto Coordinator","text":"<p>The coordinator is running in a container named <code>coordinator</code> using the <code>prestodb/presto:latest</code> image with the <code>config.properties</code> and <code>jvm.config</code> configurations under the <code>config/coordinator</code> directory along with the catalog settings in the <code>./catalog</code> directory.</p> <p>Here are the settings for the coordinator: <pre><code>coordinator=true\nnode-scheduler.include-coordinator=false\nhttp-server.http.port=8080\ndiscovery-server.enabled=true\ndiscovery.uri=http://localhost:8080\n</code></pre></p> <ul> <li><code>coordinator</code> property defines if the Presto server acts as a coordinator or not. Use value <code>true</code> for a coordinator.</li> <li><code>node-scheduler.include-coordinator</code> property defines if the Presto server acts as a worker as well as a coordinator. Use value <code>false</code>     to not accept worker tasks.</li> <li><code>http-server.http.port</code> property defines the port number for the HTTP server.</li> <li><code>discovery-server.enabled</code> property defines if the Presto server acts as a discovery server to register workers.</li> <li><code>discovery.uri</code> property defines the discovery server's URI which is itself for the coordinator.</li> </ul> <p>You can use the following command to check the logs of the coordinator: <pre><code>docker logs coordinator -n 100\n</code></pre></p> <p>If the Presto server is up and running properly, the last lines of the outputs would like the following: <pre><code>2023-11-13T23:06:41.958Z        INFO    main    com.facebook.presto.storage.TempStorageManager  -- Loading temp storage local --\n2023-11-13T23:06:41.963Z        INFO    main    com.facebook.presto.storage.TempStorageManager  -- Loaded temp storage local --\n2023-11-13T23:06:41.989Z        INFO    main    com.facebook.presto.server.PrestoServer ======== SERVER STARTED ========\n</code></pre></p> <p>You can check the Presto UI by opening a browser with this URL: http://localhost:8080</p> <p>Note</p> <p>If you run the lab on a remote server, replace the <code>localhost</code> with the server's IP address. For example <code>http://192.168.0.1:8080</code></p> <p>The page would look like this: </p>"},{"location":"lab-1/#22-worker-node-worker1","title":"2.2 Worker Node - worker1","text":"<p>The 1<sup>st</sup> worker node is named <code>worker1</code> and using the configurations under the <code>conf/worker1</code> directory with the following settings:</p> <pre><code>coordinator=false\nhttp-server.http.port=8081\ndiscovery.uri=http://coordinator:8080\n</code></pre> <ul> <li><code>coordinator</code> property is assigned the value of <code>false</code> for a worker node.</li> <li><code>http-server.http.port</code> property defines the port number for the HTTP server. Since we are running a coordinator and 3 worker nodes on     the local machine, need to use a different port for each node.</li> <li><code>discovery.uri</code> property points to the discovery server on the coordinator.</li> </ul> <p>You can use the following command to check the logs of the first worker node: <pre><code>docker logs worker1 -n 100\n</code></pre></p> <p>If the worker node is up and running properly, the last lines of the outputs would like the following: <pre><code>2023-11-14T04:03:22.246Z        INFO    main    com.facebook.presto.storage.TempStorageManager  -- Loading temp storage local --\n2023-11-14T04:03:22.251Z        INFO    main    com.facebook.presto.storage.TempStorageManager  -- Loaded temp storage local --\n2023-11-14T04:03:22.256Z        INFO    main    com.facebook.presto.server.PrestoServer ======== SERVER STARTED ========\n</code></pre></p> <p>Check the Presto UI again: http://localhost:8080. The number of active workers became <code>1</code>:</p> <p>Note</p> <p>If you run the lab on a remote server, replace the <code>localhost</code> with the server's IP address. For example <code>http://192.168.0.1:8080</code></p> <p></p>"},{"location":"lab-1/#23-worker-node-worker2","title":"2.3 Worker Node - worker2","text":"<p>The 2<sup>nd</sup> worker node is named <code>worker2</code> and using the configurations under the <code>conf/worker2</code> directory with the following settings:</p> <pre><code>coordinator=false\nhttp-server.http.port=8082\ndiscovery.uri=http://coordinator:8080\n</code></pre> <p>The settings are almost the same as `worker1, except for the port number:</p> <ul> <li><code>http-server.http.port</code> property defines the port number for the HTTP server. Since we are running a coordinator and 3 worker nodes on     the local machine, need to use a different port for each node.</li> </ul> <p>You can use the following command to check the logs of the first worker node: <pre><code>docker logs worker2 -n 100\n</code></pre></p> <p>Check the Presto UI again: http://localhost:8080. The number of active workers became <code>2</code>:</p> <p>Note</p> <p>If you run the lab on a remote server, replace the <code>localhost</code> with the server's IP address. For example <code>http://192.168.0.1:8080</code></p> <p></p>"},{"location":"lab-1/#24-worker-node-worker3","title":"2.4 Worker Node - worker3","text":"<p>The 3<sup>rd</sup> of the worker node is named <code>worker3</code> and using the configurations under the <code>conf/worker3</code> directory with the following settings:</p> <pre><code>coordinator=false\nhttp-server.http.port=8083\ndiscovery.uri=http://coordinator:8080\n</code></pre> <p>The settings are almost the same as <code>worker1</code> and <code>worker2</code>, except the port number:</p> <ul> <li><code>http-server.http.port</code> property defines the port number for the HTTP server. Since we are running a coordinator and 3 worker nodes on     the local machine, need to use a different port for each node.</li> </ul> <p>You can use the following command to check the logs of the first worker node: <pre><code>docker logs worker3 -n 100\n</code></pre></p>"},{"location":"lab-1/#3-access-the-presto-ui-on-the-coordinator","title":"3. Access the Presto UI on the Coordinator","text":"<p>You have successfully set up a Presto cluster with a coordinator and 3 worker nodes. Check the Presto UI again: http://localhost:8080.  The number of active workers became <code>3</code>:</p> <p>Note</p> <p>If you run the lab on a remote server, replace the <code>localhost</code> with the server's IP address. For example <code>http://192.168.0.1:8080</code></p> <p></p> <p>Well done! Let's move to the next lab to set up data sources.</p>"},{"location":"lab-2/","title":"Set up Data Sources","text":"<p>In this section, you will set up MongoDB and MySQL as the data sources.</p> <p>This section is comprised of the following steps:</p> <ol> <li>Set Up MongoDB</li> <li>Set Up MySQL</li> </ol>"},{"location":"lab-2/#1-mongodb","title":"1. MongoDB","text":"<p>You can use the following command to check the logs of the MongoDB: <pre><code>docker logs presto-mongo -n 100\n</code></pre></p> <p>The MongoDB is up and ready when you see the following messages: <pre><code>{\"t\":{\"$date\":\"2023-11-14T06:48:23.625+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":23015,   \"ctx\":\"listener\",\"msg\":\"Listening on\",\"attr\":{\"address\":\"0.0.0.0\"}}\n{\"t\":{\"$date\":\"2023-11-14T06:48:23.626+00:00\"},\"s\":\"I\",  \"c\":\"NETWORK\",  \"id\":23016,   \"ctx\":\"listener\",\"msg\":\"Waiting for connections\",\"attr\":{\"port\":27017,\"ssl\":\"off\"}}\n{\"t\":{\"$date\":\"2023-11-14T06:48:23.649+00:00\"},\"s\":\"I\",  \"c\":\"INDEX\",    \"id\":20345,   \"ctx\":\"LogicalSessionCacheRefresh\",\"msg\":\"Index build: done building\",\"attr\":{\"buildUUID\":null,\"collectionUUID\":{\"uuid\":{\"$uuid\":\"41f44999-9108-4497-9442-c0baba8a82c6\"}},\"namespace\":\"config.system.sessions\",\"index\":\"_id_\",\"ident\":\"index-5--8644828660937270733\",\"collectionIdent\":\"collection-4--8644828660937270733\",\"commitTimestamp\":null}}\n{\"t\":{\"$date\":\"2023-11-14T06:48:23.649+00:00\"},\"s\":\"I\",  \"c\":\"INDEX\",    \"id\":20345,   \"ctx\":\"LogicalSessionCacheRefresh\",\"msg\":\"Index build: done building\",\"attr\":{\"buildUUID\":null,\"collectionUUID\":{\"uuid\":{\"$uuid\":\"41f44999-9108-4497-9442-c0baba8a82c6\"}},\"namespace\":\"config.system.sessions\",\"index\":\"lsidTTLIndex\",\"ident\":\"index-6--8644828660937270733\",\"collectionIdent\":\"collection-4--8644828660937270733\",\"commitTimestamp\":null}}\n</code></pre></p> <p>Load the testing data into the MongoDB: <pre><code>docker exec -i presto-mongo mongosh &lt; data/mongo.sql\n</code></pre></p> <p>Check the testing data by using the following command: <pre><code>echo 'db.book.find({})' | docker exec -i presto-mongo mongosh mongodb://127.0.0.1:27017/presto_to_mongodb\n</code></pre></p> <p>You should see the following outputs: <pre><code>presto_to_mongodb&gt; [\n  {\n    _id: ObjectId(\"655318f02a5ca499ace274d5\"),\n    id: 1,\n    book_name: 'harry potter'\n  },\n  {\n    _id: ObjectId(\"655318f02a5ca499ace274d6\"),\n    id: 2,\n    book_name: 'The forgotten'\n  },\n  {\n    _id: ObjectId(\"655318f02a5ca499ace274d7\"),\n    id: 3,\n    book_name: 'The Alchemist'\n  },\n  {\n    _id: ObjectId(\"655318f02a5ca499ace274d8\"),\n    id: 4,\n    book_name: 'Engines of Liberty'\n  }\n]\n</code></pre></p>"},{"location":"lab-2/#2-mysql","title":"2. MySQL","text":"<p>You can use the following command to check the logs of the MySQL server: <pre><code>docker logs presto-mysql -n 100\n</code></pre></p> <p>The MySQL server is up and ready when you see the following message from the logs: <pre><code>2023-11-14T06:05:19.091785Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.1.0'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server - GPL.\n</code></pre></p> <p>Load the testing data into the MySQL server: <pre><code>docker exec -i presto-mysql mysql -u root --password=presto -t &lt; data/mysql.sql\n</code></pre></p> <p>A new database named <code>presto_to_mysql</code> was created and testing data was populated into the <code>author</code> table.</p> <p>Use the following command to check the testing data: <pre><code>docker exec -it presto-mysql mysql -u root --password=presto -D presto_to_mysql  -e 'select * from author'\n</code></pre></p> <p>You should see the following outputs: <pre><code>mysql: [Warning] Using a password on the command line interface can be insecure.\n+------+--------------+\n| id   | author       |\n+------+--------------+\n|    1 | Rowlings     |\n|    2 | Holly Black  |\n|    3 | Stephen King |\n|    4 | Rick Riorden |\n+------+--------------+\n</code></pre></p> <p>Now the 2 data sources are ready for use. Let's move to the next section to understand how Presto connects to these 2 data sources.</p>"},{"location":"lab-3/","title":"Connect to Data Sources","text":"<p>Presto provides a plug-and-play mechanism to set up data source connections. Presto supports many different data sources by default. You can easily add a data source connection to the coordinator and worker nodes by providing corresponding data source properties in the <code>&lt;server root&gt;/etc/catalog</code> directory. In this section, you will learn how to set up MySQL and MongoDB data sources in a Presto cluster.</p> <p>This section is comprised of the following steps:</p> <ol> <li>Data Source Connectors</li> <li>MySQL and MongoDB Connectors</li> <li>Federated Query</li> </ol>"},{"location":"lab-3/#1-data-source-connectors","title":"1. Data Source Connectors","text":"<p>First, let's learn how to run Presto CLI to connect to the coordinator. There are several ways to do that:</p> <ol> <li>Download the executable jar from the official repository and run the jar file with a proper JVM.   You can see details in this documentation.</li> <li>Use the <code>presto-cli</code> that comes with the <code>prestodb/presto</code> Docker image</li> </ol> <p>For this lab, since we run everything on Docker containers, we are going to use the second approach. You also have two ways to do this:</p> <p>Run the <code>presto-cli</code> inside the coordinator container <pre><code>docker exec -ti coordinator /opt/presto-cli\n</code></pre></p> <p>You see the Presto CLI prompt like this: <pre><code>presto&gt;\n</code></pre></p> <p>Note</p> <p>Since the <code>presto-cli</code> is executed inside the <code>coordinator</code> and <code>localhost:8080</code> is the default server, no need to specify the <code>--server</code> argument.</p> <p>Or run the <code>presto-cli</code> with a dedicated container and connect to the coordinator. <pre><code>$ docker run --rm -ti -v ./conf/coordinator/config.properties:/opt/presto-server/etc/config.properties \\\n    -v ./conf/coordinator/jvm.config:/opt/presto-server/etc/jvm.config --net presto_network \\\n    --entrypoint /opt/presto-cli prestodb/presto:latest --server coordinator:8080\npresto&gt;\n</code></pre></p> <p>After you run the command after the shell prompt, the dollar sign, you should get the <code>presto&gt;</code> CLI prompt. Then you can run this SQL - <pre><code>show catalogs;\n</code></pre> to get currently configured catalogs: <pre><code>presto&gt; show catalogs;\n Catalog\n---------\n jmx\n memory\n mongodb\n mysql\n system\n tpcds\n tpch\n(7 rows)\n\nQuery 20231115_045608_00002_xuury, FINISHED, 3 nodes\nSplits: 53 total, 53 done (100.00%)\n[Latency: client-side: 357ms, server-side: 305ms] [0 rows, 0B] [0 rows/s, 0B/s]\n\npresto&gt;\n</code></pre></p> <p>These are the catalogs that you set when launching the coordinator and worker containers by using the configurations from the <code>./catalog</code> directory.</p> <ul> <li>jmx: The JMX connector provides the ability to query JMX   information from all nodes in a Presto cluster.</li> <li>memory: The Memory connector stores all data and metadata   in RAM on workers and both are discarded when Presto restarts.</li> <li>system: The System connector provides information and   metrics about the currently running Presto cluster.</li> <li>tpcds: The TPCDS connector provides a set of schemas   to support the TPC Benchmark\u2122 DS (TPC-DS)</li> <li>tpch: The TPCH connector provides a set of schemas to   support the TPC Benchmark\u2122 H (TPC-H).</li> </ul>"},{"location":"lab-3/#2-mysql-and-mongodb-connectors","title":"2. MySQL and MongoDB Connectors","text":"<p>Adding new catalogs to Presto servers is quite simple. You just need to create the corresponding property file under <code>&lt;presto-root&gt;/etc/catalog</code> directory and provide the data source information in the property file.</p> <p>For the MySQL database, you can find the following content in the <code>./catalog/mysql.properties</code> file. It contains the information about the MySQL database you set up earlier.</p> <pre><code>connector.name=mysql\nconnection-url=jdbc:mysql://presto-mysql:3306\nconnection-user=root\nconnection-password=presto\n</code></pre> <p>For the MongoDB, you can find the following content in the <code>./catalog/mongodb.properties</code> file. It contains the information about the MongoDB you set up earlier:</p> <pre><code>connector.name=mongodb\nmongodb.seeds=presto-mongo:27017\n</code></pre>"},{"location":"lab-3/#3-federated-query","title":"3. Federated Query","text":"<p>Let's run some SQLs to verify the MySQL and MongoDB data sources:</p> <ul> <li>List the schemas in the MongoDB:   <pre><code>show schemas in mongodb;\n</code></pre>   Outputs:   <pre><code> presto&gt; show schemas in mongodb;\n       Schema\n--------------------\n admin\n config\n information_schema\n local\n presto_to_mongodb\n(5 rows)\n\nQuery 20231115_054817_00001_hwb7z, FINISHED, 4 nodes\nSplits: 53 total, 53 done (100.00%)\n[Latency: client-side: 0:01, server-side: 0:01] [5 rows, 76B] [6 rows/s, 105B/s]\n</code></pre></li> <li>Show all records in the <code>book</code> document from MongoDB:   <pre><code>select * from mongodb.presto_to_mongodb.book;\n</code></pre>   Outputs:   <pre><code>presto&gt; select * from mongodb.presto_to_mongodb.book;\n id |     book_name\n----+--------------------\n  1 | harry potter\n  2 | The forgotten\n  3 | The Alchemist\n  4 | Engines of Liberty\n(4 rows)\n\nQuery 20231115_055124_00003_hwb7z, FINISHED, 1 node\nSplits: 17 total, 17 done (100.00%)\n[Latency: client-side: 381ms, server-side: 365ms] [4 rows, 112B] [10 rows/s, 306B/s]\n</code></pre></li> </ul> <p>Note</p> <p>You may run this command <code>use mongodb.presto_to_mongodb;</code> to switch to the <code>mongodb</code> catalog and use <code>presto_to_mongodb</code> as the default schema. Then use <code>book</code> in the SQL instead of <code>mongodb.presto_to_mangodb.book</code>.</p> <ul> <li>List the schemas in MySQL:   <pre><code>show schemas in mysql;\n</code></pre>   Outputs:   <pre><code>presto&gt; show schemas in mysql;\n       Schema\n--------------------\n information_schema\n performance_schema\n presto_to_mysql\n sys\n(4 rows)\n\nQuery 20231115_055417_00004_hwb7z, FINISHED, 4 nodes\nSplits: 53 total, 53 done (100.00%)\n[Latency: client-side: 0:01, server-side: 0:01] [4 rows, 74B] [4 rows/s, 82B/s]\n</code></pre></li> <li>Show all records in the <code>author</code> table from MySQL:   <pre><code>select * from mysql.presto_to_mysql.author;\n</code></pre>   Outputs:   <pre><code>presto&gt; select * from mysql.presto_to_mysql.author;\n id |    author\n----+--------------\n  1 | Rowlings\n  2 | Holly Black\n  3 | Stephen King\n  4 | Rick Riorden\n(4 rows)\n\nQuery 20231115_055652_00006_hwb7z, FINISHED, 2 nodes\nSplits: 17 total, 17 done (100.00%)\n[Latency: client-side: 0:01, server-side: 0:01] [4 rows, 0B] [5 rows/s, 0B/s]\n</code></pre></li> <li>Finally, join the tables from MySQL and MongoDB - a federated query using this SQL:   <pre><code>select A.id, A.author, B.book_name from mysql.presto_to_mysql.author A\n  join mongodb.presto_to_mongodb.book B on A.id=B.id order by A.id;\n</code></pre>   Here are the results:   <pre><code>presto&gt; select A.id, A.author, B.book_name from mysql.presto_to_mysql.author A join mongodb.presto_to_mongodb.book B on A.id=B.id order by A.id;\n id |    author    |     book_name\n----+--------------+--------------------\n  1 | Rowlings     | harry potter\n  2 | Holly Black  | The forgotten\n  3 | Stephen King | The Alchemist\n  4 | Rick Riorden | Engines of Liberty\n(4 rows)\n\nQuery 20231115_060032_00010_hwb7z, FINISHED, 3 nodes\nSplits: 198 total, 198 done (100.00%)\n[Latency: client-side: 0:01, server-side: 0:01] [8 rows, 112B] [14 rows/s, 208B/s]\n</code></pre></li> </ul> <p>You just used the unified SQL to query data from two different data sources and leverage the Presto SQL engine to perform a federated query that joins two data sets from two data sources.</p>"},{"location":"lab-4/","title":"Data Visualization","text":"<p>You've learned how to set up a Presto cluster, connect to multiple data sources, and run federate queries. The main reasons that you can easily do these are:</p> <ul> <li>Presto provides many built-in data source connectors</li> <li>One single language: SQL</li> <li>Optimize performance for large-scale distributed workload</li> </ul> <p>Also, because of these features, it becomes very easy to integrate a data visualization tool with Presto. In this section, you will learn how to set up Apache Zeppelin to connect to the Presto cluster and run data analytics and visualization.</p> <p>This section is comprised of the following steps:</p> <ol> <li>Set up Apache Zeppelin</li> <li>Data Visualization</li> </ol>"},{"location":"lab-4/#1-set-up-apache-zeppelin","title":"1. Set up Apache Zeppelin","text":""},{"location":"lab-4/#use-the-offical-docker-image","title":"Use the Offical Docker Image","text":"<p>You can use the following command to check the container logs: <pre><code>docker logs -n 100 zeppelin\n</code></pre></p> <p>You can access http://localhost:8443 on a browser to access the dashboard, like this:</p> <p>Note</p> <p>If you run the lab on a remote server, replace the <code>localhost</code> with the server's IP address. For example <code>http://192.168.0.1:8443</code></p> <p></p>"},{"location":"lab-4/#add-presto-jdbc-driver","title":"Add Presto JDBC Driver","text":"<p>Thanks to the Presto JDBC Driver, you can easily integrate Apache Zeppelin with Presto.</p> <ol> <li> <p>Click on the <code>anonymous</code> in the upper-right corner and select <code>interpreter</code> on the pop-up    menu:</p> <p></p> </li> <li> <p>Create a new interpreter by clicking the <code>Create</code> button under the <code>anonymous</code>:</p> <p></p> </li> <li> <p>Use presto for the <code>Interpreter Name</code>, meaning you need to use %presto as a directive    on the first line of a paragraph in a Zeppelin notebook. Then select jdbc as the    <code>Interpreter group</code>:</p> <p></p> </li> <li> <p>Have the following settings in the <code>Properties</code> section:</p> <ul> <li><code>default.url</code>: jdbc:presto://coordinator:8080/</li> <li><code>default.user</code>: zeppelin</li> <li><code>default.driver</code>: com.facebook.presto.jdbc.PrestoDriver</li> </ul> <p></p> </li> <li> <p>Scroll down to the <code>Dependencies</code> section and use the maven URI to point to the Presto    JDBC driver - com.facebook.presto:presto-jdbc:0.290. Click the <code>Save</code> button to    save the settings.</p> <p></p> </li> </ol> <p>You have created an interpreter to talk to the Presto cluster.</p> <p>Note</p> <p>The interpreter connects the Presto without a specific catalog and schema. When using the <code>%presto</code> interpreter, you have to specify the catalog and schema in your SQL or run <code>use &lt;catalog&gt;.&lt;schema&gt;;</code> first.</p>"},{"location":"lab-4/#2-data-visualization","title":"2. Data Visualization","text":"<p>Apache Zeppelin is a web-based notebook that enables data-driven, interactive data analytics and collaborative documents with SQL, Scala, Python, R and more. Here, we just show you how easily to leverage Presto to run data analytics and visualization.</p> <ol> <li> <p>Create a Zeppelin note by clicking the <code>Notebook</code> on the top nav menu and selecting <code>Create new</code> note`:</p> <p></p> </li> <li> <p>Name it as presto and select presto as the <code>Default Interpreter</code>. Click the <code>Create</code> button.</p> <p></p> </li> <li> <p>Copy and paste the following SQL to the first paragraph of the note:    <pre><code>use tpch.sf1; SELECT n.name, sum(l.extendedprice * (1 - l.discount)) AS revenue FROM \"customer\" AS c, \"orders\" AS o, \"lineitem\" AS l, \"supplier\" AS s, \"nation\" AS n, \"region\" AS r WHERE c.custkey = o.custkey AND l.orderkey = o.orderkey AND l.suppkey = s.suppkey AND c.nationkey = s.nationkey AND s.nationkey = n.nationkey AND n.regionkey = r.regionkey AND r.name = 'ASIA' AND o.orderdate &gt;= DATE '1994-01-01' AND o.orderdate &lt; DATE '1994-01-01' + INTERVAL '1' YEAR GROUP BY n.name ORDER BY revenue DESC;\n</code></pre></p> <p>Then click the <code>triangle</code> run button on the top menu bar or the upper-right corner of the first paragraph.</p> <p></p> </li> <li> <p>After the query finishes, the results will show up below the SQL.</p> <p></p> </li> <li> <p>You can select different built-in charts to visualize the results.</p> <p></p> </li> </ol>"},{"location":"lab-5/","title":"Presto Helm Charts","text":""},{"location":"lab-5/#use-helm-to-deply-a-presto-cluster","title":"Use Helm to Deply a Presto Cluster","text":"<p>The Presto community also provides the helm chart to install Presto cluster on a Kubernetes cluster. Here is how you can leverage it to create a Presto cluster containing the same settings for this workshop.</p>"},{"location":"lab-5/#prerequisite","title":"Prerequisite","text":"<p>In order to use Presto helm chart, make sure the following tools are available</p> <ul> <li>Helm</li> <li>A Kubernetes cluster: use kind for the lab</li> <li>kubectl</li> </ul>"},{"location":"lab-5/#optional-create-a-kind-cluster","title":"Optional: Create a kind Cluster","text":"<p>Use the following command to create a kind cluster named <code>presto</code>:</p> <pre><code>kind create cluster -n presto\n</code></pre>"},{"location":"lab-5/#instructions","title":"Instructions","text":"<ol> <li> <p>Add the Presto Helm Chart Repository:</p> <p>Helm chart repository is a location where packaged charts can be stored and shared. Use the following command to add Presto charts repository to Helm client configuration: <pre><code>helm repo add presto https://prestodb.github.io/presto-helm-charts\n</code></pre> List the latest stable versions of available Helm charts with the command: <pre><code>helm search repo presto\n</code></pre> Sample outputs: <pre><code>NAME            CHART VERSION   APP VERSION     DESCRIPTION\npresto/presto   0.4.0           0.291           The official Helm chart for Presto\n</code></pre></p> </li> <li> <p>Create a namespace for the Presto cluster</p> <p>Use a dedicate namespace to deploy the Presto cluster. In this case, the namespace is called <code>presto</code> <pre><code>kubectl create ns presto\n</code></pre></p> </li> <li> <p>To avoid Docker hub rate limitation, create a default Docker image pull secret based on your docker config.    Make sure the docker config file exist by running the following command:    <pre><code>docker login\n</code></pre>    Create the secret using the docker config file:    <pre><code>kubectl create secret generic regcred \\\n       --from-file=.dockerconfigjson=/path/to/your/.docker/config.json \\\n       --type=kubernetes.io/dockerconfigjson \\\n       --namespace presto\n</code></pre>    Make the secret as the default secret for pulling image:    <pre><code>kubectl patch serviceaccount default -p '{\"imagePullSecrets\": [{\"name\": \"regcred\"}]}' \\\n   --namespace presto\n</code></pre></p> </li> <li> <p>Deploy MongoDB and MySQL</p> <pre><code>kubectl apply -n presto -k helm/kustomize\n</code></pre> </li> <li> <p>Populate the Data into MongoDB and MySQL</p> <pre><code>kubectl exec -n presto -ti svc/presto-mongo mongosh &lt; data/mongo.sql\nkubectl exec -n presto -ti svc/presto-mysql -- mysql -u root -ppresto &lt; data/mysql.sql\n</code></pre> </li> <li> <p>Install a Presto Chart</p> <p>Install a Presto Helm chart and it will provision a Presto cluster using the settings from the <code>helm/values.yaml</code> <pre><code>helm install presto presto/presto -f helm/values.yml -n presto\n</code></pre> See the refernece of the values.yml here</p> <p>Wait for a while for the Presto pods, including coordinator and workers, to be ready: <pre><code>NAME                                  READY   STATUS    RESTARTS   AGE\npresto-coordinator-68dff7c554-9dxbw   1/1     Running   0          20h\npresto-mongo-846c4ff7c5-j5thm         1/1     Running   0          20h\npresto-mysql-765d566f59-jtqtg         1/1     Running   0          20h\npresto-worker-9f99c6d69-d4djp         1/1     Running   0          20h\npresto-worker-9f99c6d69-hnxqx         1/1     Running   0          20h\npresto-worker-9f99c6d69-thslm         1/1     Running   0          20h\n</code></pre> The configuration would bring up 1 coordinator and 3 workers pods.</p> </li> <li> <p>Access the Presto UI</p> <p>Run the following command to port-forward the port <code>8080</code> of the <code>presto</code> service: <pre><code>kubectl port-forward -n presto svc/presto --address 0.0.0.0 8080:08080\n</code></pre> Then you can access the Presto UI at <code>http://localhost:808</code></p> </li> </ol>"},{"location":"prerequisite/","title":"Prerequisite","text":"<p>This workshop uses Docker to set up a Presto cluster, MySQL, and MongoDB. And it uses Docker Compose to run them all together.</p> <p>Please follow the installation links below to set up your working environment:</p> <ul> <li>Docker</li> <li>Docker Compose (Optional)</li> </ul>"},{"location":"prerequisite/#clone-the-workshop-repository","title":"Clone the workshop repository","text":"<p>Various parts of this workshop will require the configuration files from the workshop repository. Use the following command to download the whole repository <pre><code>git clone https://github.com/IBM/presto-101-lab.git\ncd presto-101-lab\n</code></pre></p> <p>Or download the repository as a zip file, unzip it and get into the <code>presto-101-lab-main</code> directory.</p>"},{"location":"resources/CONTRIBUTORS/","title":"Contributors","text":""},{"location":"resources/CONTRIBUTORS/#kiersten-stokes","title":"Kiersten Stokes","text":"<ul> <li>Github: kiersten-stokes</li> </ul>"},{"location":"resources/CONTRIBUTORS/#yihong-wang","title":"Yihong Wang","text":"<ul> <li>Github: yhwang</li> </ul>"},{"location":"resources/RESOURCES/","title":"Additional resources","text":""},{"location":"resources/RESOURCES/#presto","title":"Presto","text":"<ul> <li>Presto</li> <li>Presto Documentation</li> <li>Prestocon 2023 Workshop Slides</li> </ul>"},{"location":"resources/SCALE/","title":"Scalability","text":""},{"location":"resources/SCALE/#scaling-a-presto-cluster","title":"Scaling a Presto Cluster","text":"<p>The purpose of the scaling a Presto cluster is to handle an increased workload for certain scenarios. Usually you need to scale up the Presto cluster because:</p> <ul> <li>Number of users increases</li> <li>Number of queries increase</li> <li>The volume of data increases</li> </ul> <p>Some situations also indicate a need of scaling:</p> <ul> <li>Single point of failure</li> <li>Bad worker state: out-of-memory errors occurs and corresponding queries fail, thus wasting resources.</li> <li>Bad queiries: A SQL query takes too long to execute and starves the other queries for resources.</li> </ul>"},{"location":"resources/SCALE/#vertical-scaling","title":"Vertical Scaling","text":"<p>One of the scaling approach is to increase the resources in a single server, i.e. CPU, memory, or storage size.</p> Query type Resources to increase Store large amount of data in memory Memory Complex calculation/computation CPU <ul> <li>Memory:<ul> <li>Need to allocate more memory to a Presto node. The <code>-Xmx</code> property in the <code>jvm.config</code> configuration.</li> <li><code>query.max-memory-per-node</code> in the <code>config.properties</code></li> </ul> </li> <li>CPU:<ul> <li><code>task.concurrency</code> in the <code>config.properties</code>: define the number of worker thread per node.</li> </ul> </li> </ul>"},{"location":"resources/SCALE/#availability","title":"Availability","text":"<ul> <li>Use Presto Router to manage the access to multiple Presto clusters</li> <li>Set Up multiple coordinators - Disaggregated Coordinator</li> </ul>"},{"location":"resources/SCALE/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Deploy more workers.</p> <ul> <li>For instance base deployment, create or allocate a new instance, deploy Presto, add the worker node to the Presto cluster</li> <li>For Kubernetes base deployment, increase the replicate number of worker deployment.</li> <li>For cloud base deployment, check the service document and scale up.</li> </ul>"},{"location":"resources/SCALE/#presto-on-spark","title":"Presto on Spark","text":"<ul> <li>Great for large batch ETL workload because of the paralelism.</li> <li>A robust and scalable execution platform</li> <li>Get benefits from both Apache Spark and Presto</li> </ul>"}]}